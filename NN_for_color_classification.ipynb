{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_for_color_classification.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "Akc5xnURhDjk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### TensorFlow and other imports"
      ]
    },
    {
      "metadata": {
        "id": "pPws_2mthDjm",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.contrib.eager as tfe\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ralonnMyhDkC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Created a function to read the csv and separate what is feature and what is label"
      ]
    },
    {
      "metadata": {
        "id": "Izc0XeeshDkE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def parse_csv(line):\n",
        "    example_defaults = [[0.], [0.], [0.], [0]]\n",
        "    parsed_line = tf.decode_csv(line, example_defaults)\n",
        "    \n",
        "    features = tf.reshape(parsed_line[:-1], shape=(3,))\n",
        "    label = tf.reshape(parsed_line[-1], shape=())\n",
        "    \n",
        "    return features, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bTQcYL1ShDkI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.TextLineDataset(\"colorDatasetNormalized.csv\")\n",
        "train_dataset = train_dataset.skip(1)\n",
        "train_dataset = train_dataset.map(parse_csv)\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1000)\n",
        "train_dataset = train_dataset.batch(32)\n",
        "\n",
        "# View a single example entry from a batch\n",
        "features, label = iter(train_dataset).next()\n",
        "print(\"example features:\", features[0])\n",
        "print(\"example label:\", label[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ypI_MnXWhDkR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Using Keras to make the Neural Net"
      ]
    },
    {
      "metadata": {
        "id": "iZ58q1fkhDkT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    # First hidden layer\n",
        "    # Need to specify the input shape,\n",
        "    # aka the number of features\n",
        "    # the nummber of nodes and the activation function\n",
        "    tf.keras.layers.Dense(10, activation=\"relu\", input_shape=(3,)),\n",
        "    # The others hidden layers only need \n",
        "    # the quantity of nodes and the activation function\n",
        "    tf.keras.layers.Dense(10, activation=\"relu\"),\n",
        "    # Same here\n",
        "    tf.keras.layers.Dense(10, activation=\"relu\"),\n",
        "    # The last layer only need the number of nodes\n",
        "    # The number here is the number of possible outputs\n",
        "    # In this case 9 different color classes\n",
        "    tf.keras.layers.Dense(9)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OmbO9_iMhDkX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def loss(model, x, y):\n",
        "    y_ = model(x)\n",
        "    return tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)\n",
        "\n",
        "def grad(model, inputs, targets):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss(model, inputs, targets)\n",
        "    \n",
        "    return tape.gradient(loss_value, model.variables)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ERECPeQbhDka",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vS4XdI0BhDki",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_loss_results = []\n",
        "train_accuracy_results = []\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss_avg = tfe.metrics.Mean()\n",
        "    epoch_accuracy = tfe.metrics.Accuracy()\n",
        "    \n",
        "    for x, y in train_dataset:\n",
        "        grads = grad(model, x, y)\n",
        "        optimizer.apply_gradients(zip(grads, model.variables),\n",
        "                                  global_step=tf.train.get_or_create_global_step())\n",
        "        \n",
        "        epoch_loss_avg(loss(model, x, y))\n",
        "        epoch_accuracy(tf.argmax(model(x), axis=1, output_type=tf.int32), y)\n",
        "    \n",
        "    train_loss_results.append(epoch_loss_avg.result())\n",
        "    train_accuracy_results.append(epoch_accuracy.result())\n",
        "    \n",
        "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
        "                                                                epoch_loss_avg.result(),\n",
        "                                                                epoch_accuracy.result()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PrRMnTO8hDko",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
        "fig.suptitle('Training Metrics')\n",
        "\n",
        "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
        "axes[0].plot(train_loss_results)\n",
        "\n",
        "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
        "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
        "axes[1].plot(train_accuracy_results)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XaWfRlb4hDkx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class_ids = [\n",
        "    \"red-ish\",\n",
        "    \"green-ish\",\n",
        "    \"blue-ish\",\n",
        "    \"orange-ish\",\n",
        "    \"yellow-ish\",\n",
        "    \"pink-ish\",\n",
        "    \"purple-ish\",\n",
        "    \"brown-ish\",\n",
        "    \"grey-ish\"\n",
        "]\n",
        "predict_data = tf.convert_to_tensor([\n",
        "    [0.949019608, 0.917647059, 0.980392157], # pink-ish\n",
        "    [0.537254902, 0.996078431, 0.549019608], # green-ish\n",
        "    [0.466666667, 0.525490196,0.278431373], # I think its blue-ish\n",
        "])\n",
        "\n",
        "predictions = model(predict_data)\n",
        "\n",
        "for i, logits in enumerate(predictions):\n",
        "    class_idx = tf.argmax(logits).numpy()\n",
        "    name = class_ids[class_idx]\n",
        "    print(\"Example {} prediction: {}\".format(i, name))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}